{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45c1da01-676d-4693-ad43-746575285746",
   "metadata": {},
   "source": [
    "# DNN Retrieval Model\n",
    "\n",
    "#### Two-Tower Model for Learning Query and Candidate Embeddings\n",
    "\n",
    "References: \n",
    "- https://www.tensorflow.org/recommenders/examples/basic_retrieval\n",
    "- https://storage.googleapis.com/pub-tools-public-publication-data/pdf/6c8a86c981a62b0126a11896b7f6ae0dae4c3566.pdf\n",
    "_____\n",
    "\n",
    "In this notebook, we will build a Two-Tower DNN Model system to recommend a set of courses from an online catalogue that a given user is likely to watch. One of the advantages of building a Deep Learning Recommendation engine is the ability to build rich, flexible feature representations.\n",
    "\n",
    "## DNN: Retrival and Rankng Architecture \n",
    "\n",
    "![](../docs/assets/deep_retrieval.png) \n",
    "\n",
    "### I. Retrieval \n",
    "\n",
    "Stage is responsible for selecting an initial set of hundreds of candidates from all candidates and efficiently filter out candidates that a user is not interested in. Because the retrieval model could consists of millions of users and items, it has to be computationally efficient. We'll discuss more below on optimizing this stage, but first there are two main components of the retrieval model:\n",
    "\n",
    "**1. Query Model**: computes the query representation (normally a fixed-dimensionality embedding vector) using query features. A query fearture could consist of, but not limited to the the following:\n",
    "\n",
    "- unique id\n",
    "- title\n",
    "- previous_history\n",
    "- content viewing time\n",
    "- likes\n",
    "- ratings\n",
    "- view date\n",
    "\n",
    "**2. Candidate model** computes the candidate representation (an equally-sized vector) using the candidate features. A candidate fearture could consist of:\n",
    "\n",
    "- uqniue id\n",
    "- title\n",
    "\n",
    "\n",
    "The process in the retrieval stage is to translate User and Item ids into embedding vectors, which are just high-dimensional numerical representations. The weights for the embedding layers are adjuste during training and the outputs of the two models are then multiplied together to give a query-candidate affinity score, with higher scores expressing a better match between the candidate and the query.\n",
    "\n",
    "### II. Ranking\n",
    "\n",
    "Stage takes the outputs of the retrieval model and fine-tunes them to a much smaller subset of recommendations. For the ranking stage, one of the main differences with this architecture is the ability to substantially improve the recommendations by using more features rather than just user and candidate identifiers. We can include features about the candidate such as:\n",
    "\n",
    "- prices\n",
    "- genres\n",
    "- posted time\n",
    "\n",
    "_______\n",
    "Keep in mind that **Matrix Factorization** `user_id` and `candidate_id` features collaboratively to learn the latent features and does not consider side-features like mentioned above, and thus may not be highly performant. We can use deep learnning architectures such as the two-tower nerual network to include side features into the model as shown below.\n",
    "\n",
    "![](../docs/assets/two_tower_model.png) \n",
    "\n",
    "![](../docs/assets/two_tower_model2.png) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcbfae8-1081-4968-b83e-8551e7d37cd3",
   "metadata": {},
   "source": [
    "________\n",
    "### Evaluate Model\n",
    "\n",
    "The training data contains positive (user, item) pairs. To evaluate the mode, we need to compare the affinity score that the model calculates for this pair to the scores of all the other possible candidates. So if the score for the positive pair is higher than for all other candidates, our model is highly accurate. The metric we will be using to evaluate the model is:\n",
    "\n",
    "- **Metrics:** The metric utilized for evaluating the model is [factorized_top_k.TopK](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/metrics/FactorizedTopK), which computes the top K categorical accuracy: how often the true candidate is in the top K candidates for a given query.\n",
    "\n",
    "    - As the model trains, the top-k retrieval metrics updates. The `factorized_top_k` retrieval metric measures the number of true positive that is in the top-k retrieved items from the entire candidate set. As an example, a top-5 categorical accuracy metric of 0.2 would tell us that, on average, the true positive is in the top 5 retrieved items 20% of the time.\n",
    "\n",
    "        - **Recall:** the ratio of items that a user likes were actually recommended. If a user likes say 5 items and the recommendation shows 3 of them, then the recall is 0.60.\n",
    "\n",
    "        - **Precision:** out of all the recommended items, how many the user actually liked? If 5 items were recommended to the user out of which he liked, say 4 of them, then the precision is 0.80.\n",
    "\n",
    "         - So we if we recommend all items to a user, then we have 100% recall! If we recommend say 1000 items and the user only likes 10, the precision is 0.10%, which is very low. \n",
    "\n",
    "        - **Goal:** Maximize both the precision and recall. \n",
    "\n",
    "- **Loss Function**: The loss function [tfrs.tasks.Retrieval](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/tasks/Retrieval) will try to maximize the affinity of these query, candidate pairs while minimizing the affinity between the query and candidates belonging to other queries in the batch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "037d0ce1-e125-4199-82eb-999a976e98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/tracesmith/Desktop/Trace/Coding/user-recommender\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "160aad10-3e3e-44f0-b2a8-85c35fbeb090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "from recommenders.retrieval import retrieval_main, QueryModel, CandidateModel\n",
    "from recommenders.utils.plots import plot_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd6f173-8a5c-40c2-bb37-08a1b24e2f95",
   "metadata": {},
   "source": [
    "### Build Dataset\n",
    "\n",
    "For this example, the dataset we will focus on is `user_course_views.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f41b208d-388f-442b-92f3-4c3670479588",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User content\n",
    "user_course_views = pd.read_csv(os.path.join('data','user_course_views.csv'))\n",
    "course_tags = pd.read_csv(os.path.join('data','course_tags.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c943ae5b-4c38-4f36-b8a8-cf2e4a1012ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_course_views['course_id'] = user_course_views['course_id'].apply(lambda x: ' '.join(x.split('-')))\n",
    "courses = user_course_views[['course_id','author_handle','level']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fed4f023-4166-48ba-8681-574019c151aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-29 20:01:51.256160: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Users --> Convert to Tensors\n",
    "user_id = tf.convert_to_tensor(user_course_views['user_handle'].astype(str), dtype=tf.string)\n",
    "users_watched_courses = tf.convert_to_tensor(user_course_views['course_id'].astype(str), dtype=tf.string)\n",
    "users_watched_courses_view_time = tf.convert_to_tensor(user_course_views['view_time_seconds'].astype(str), dtype=tf.int64)\n",
    "tensors = {'user_id':user_id,'title':users_watched_courses,'user_view_time':users_watched_courses_view_time}\n",
    "users = tf.data.Dataset.from_tensor_slices(tensors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6bbb5c0-52c3-4de6-a23a-1b2aef853025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courses --> Convert to Tensors\n",
    "course_ids = tf.convert_to_tensor(courses['course_id'].astype(str), dtype=tf.string)\n",
    "tensors = {'title':course_ids}\n",
    "courses = tf.data.Dataset.from_tensor_slices(tensors)\n",
    "courses = courses.map(lambda x: x['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429373c1-19ec-42a7-b963-a343f7228319",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94a29a8-6f3a-45de-8f4d-5997c97a19db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "model,history = retrieval_main(users,\n",
    "                       courses,\n",
    "                       epochs=10,\n",
    "                       learning_rate=0.10,\n",
    "                       batch_size=1_000,\n",
    "                       split_ratio=0.80,\n",
    "                       top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d001bb-0b8a-4d1c-9e99-9ec9abc7c3f1",
   "metadata": {},
   "source": [
    "### Model Prediction\n",
    "\n",
    "- To answer a query with this approach, the system must first map the query to the embedding space.\n",
    "\n",
    "- Here we perform an exhaustive search of the neighbors in an embedding vector. This means iterating over all possible items and computing the distance for each one of them to our query point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "15dee4be-9a05-4e20-b5b0-61e546aad8f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow_recommenders.layers.factorized_top_k.BruteForce at 0x167b65040>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfrs.layers.factorized_top_k.BruteForce(model.query_model,k=5)\n",
    "brute_force.index(courses.batch(1_0000).map(model.candidate_model),courses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dacb6d1-f819-41aa-bdb2-d7f50b6e733e",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4caf2524-a58c-4e62-b474-df94342ac299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/ky/49p8hmz15hxchr2k1kvm6thm0000gn/T/tmpvky54kzc\n"
     ]
    }
   ],
   "source": [
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    retrieval_model_path = os.path.join(tmp_dir, \"retrieval_model\")\n",
    "brute_force.save('models')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469a12a6-9a95-45bd-aced-175128fe3fef",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c37e86d-aacc-4f43-bdc7-5cef4fb653a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "plot_metrics(history,['factorized_top_k/top_5_categorical_accuracy','factorized_top_k/top_10_categorical_accuracy',\n",
    "                      'factorized_top_k/top_50_categorical_accuracy','factorized_top_k/top_100_categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b194e72-014c-4126-a6d5-3a0758d1ad68",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4424c75f-a3bd-450d-9cc3-4c2993b0b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "query_model_2 (QueryModel)   multiple                  280355    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              multiple                  1088      \n",
      "=================================================================\n",
      "Total params: 281,443\n",
      "Trainable params: 281,440\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.query_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "949d3ffe-8290-44d8-b0d8-7e0901feadb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_14\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "candidate_model_2 (Candidate (None, 64)                222176    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 32)                2080      \n",
      "=================================================================\n",
      "Total params: 224,256\n",
      "Trainable params: 224,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.candidate_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6649bb-6861-44d0-ab9c-4e0e924b3060",
   "metadata": {},
   "source": [
    "### Recommendations\n",
    "\n",
    "To make a prediction, a query model takes in the features of the query and transforming them into a query embedding, and a candidate model. \n",
    "\n",
    "- As mentioned, we will be using [tfrs.layers.factorized_top_k.BruteForce](https://www.tensorflow.org/recommenders/api_docs/python/tfrs/layers/factorized_top_k/BruteForce), but this this approach is not suitable for large scale datasets since this layer sorts the pre-computed candidate representations, and calculate the scores of the query-candidate pairs for all possible candidates, and then returns the highest `k` ranked itmes. \n",
    "\n",
    "- An alternative approach is using approximate nearest neighbours (ANN) index which allows fast approximate lookup of candidates in response to a query produced by the query model. [ScaNN (Scalable Nearest Neighbors)](https://eugeneyan.com/writing/how-to-install-scann-on-mac/) is a method for efficient vector similarity search at scale.\n",
    "\n",
    "- https://github.com/google-research/google-research/tree/master/scann"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6fbed8-98a9-41fd-a9b1-d11ddb30da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "brute_force = tf.keras.models.load_model('models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0428e273-2e00-480c-9eb6-cf49b9a7b241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'using schedules material cost estimation revit 1368',\n",
       "       b'walk cycles motionbuilder 184',\n",
       "       b'nuke green screen keying building fundamentals',\n",
       "       b'learning program better programmer',\n",
       "       b'learning program better programmer'], dtype=object)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brute_force(tf.constant(['1']))[1].numpy().ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d617f036-63d2-4bc5-a4ea-1356e768a5cb",
   "metadata": {},
   "source": [
    "### Serve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "205eeb75-55e5-40f8-9799-258716e41ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -p 8501:8501 -v \"/models\" -e MODEL_NAME=retrieval -t tensorflow/serving &"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pluaral",
   "language": "python",
   "name": "pluaral"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
